{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"4 - Troubleshooting and Debugging.ipynb","provenance":[{"file_id":"https://github.com/geoffwoollard/gpu-speedups-mbptechtalk2020/blob/master/5%20-%20Troubleshooting%20and%20Debugging.ipynb","timestamp":1580071690258}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"f_vp0XI6nDwA","colab_type":"text"},"source":["# MBP Tech Talk 2020 :: Troubleshooting and Debugging\n","\n","## Note about the Terminal\n","\n","Debugging is an important part of programming.  Unfortuntely, it is pretty difficult to debug CUDA kernels directly in the Jupyter notebook for a variety of reasons, so this notebook will show terminal commands by executing Jupyter notebook cells using the shell.  These shell commands will appear in notebook cells with the command line prefixed by `!`. When applying the debug methods described in this notebook, you will likely run the commands in the terminal directly.\n","\n","## Printing\n","\n","A common debugging strategy is printing to the console.  Numba supports printing from CUDA kernels, with some restrictions.  Note that output printed from a CUDA kernel will not be captured by Jupyter, so you will need to debug with a script you can run from the terminal.\n","\n","Let's look at a CUDA kernel with a bug:"]},{"cell_type":"code","metadata":{"id":"b3t9MjX_uR5g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"9d468e9b-46e9-4fce-d73a-4aefc1304ae3","executionInfo":{"status":"ok","timestamp":1580073620529,"user_tz":300,"elapsed":22177,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6V0_wclOuhK8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"2fef756e-a41c-4107-9fdc-e3c5b052903c","executionInfo":{"status":"ok","timestamp":1580073853485,"user_tz":300,"elapsed":680,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["\n","%cd /content/drive/My\\ Drive/mbp\n","#!git clone https://github.com/geoffwoollard/gpu-speedups-mbptechtalk2020.git\n","%cd gpu-speedups-mbptechtalk2020"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/mbp\n","/content/drive/My Drive/mbp/gpu-speedups-mbptechtalk2020\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J_YTgTH3nDwE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":476},"outputId":"c3157273-3d27-4a63-bd18-1bd6231be6f7","executionInfo":{"status":"ok","timestamp":1580073860769,"user_tz":300,"elapsed":4639,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["! cat debug/ex1.py"],"execution_count":16,"outputs":[{"output_type":"stream","text":["import numpy as np\n","\n","from numba import cuda\n","\n","@cuda.jit\n","def histogram(x, xmin, xmax, histogram_out):\n","    nbins = histogram_out.shape[0]\n","    bin_width = (xmax - xmin) / nbins\n","\n","    start = cuda.grid(1)\n","    stride = cuda.gridsize(1)\n","\n","    for i in range(start, x.shape[0], stride):\n","        bin_number = np.int32((x[i] - xmin)/bin_width)\n","        if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n","            histogram_out[bin_number] += 1\n","\n","x = np.random.normal(size=50, loc=0, scale=1).astype(np.float32)\n","xmin = np.float32(-4.0)\n","xmax = np.float32(4.0)\n","histogram_out = np.zeros(shape=10, dtype=np.int32)\n","\n","histogram[64, 64](x, xmin, xmax, histogram_out)\n","\n","print('input count:', x.shape[0])\n","print('histogram:', histogram_out)\n","print('count:', histogram_out.sum())\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"AXH9WwFYnDwK","colab_type":"text"},"source":["When we run this code to histogram 50 values, we see the histogram is not getting 50 entries: "]},{"cell_type":"code","metadata":{"id":"lhZLSx0pnDwL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"ceca3180-2bd5-4470-8d0b-5afc70907302","executionInfo":{"status":"ok","timestamp":1580073902545,"user_tz":300,"elapsed":6103,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["! python debug/ex1.py"],"execution_count":17,"outputs":[{"output_type":"stream","text":["input count: 50\n","histogram: [0 0 1 1 1 1 1 1 0 0]\n","count: 6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mP9UmI4hnDwO","colab_type":"text"},"source":["*(You might have already spotted the mistake, but let's pretend we don't know the answer.)*\n","\n","We hypothesize that maybe a bin calculation error is causing many of the histogram entries to appear out of range.  Let's add some printing around the `if` statement to show us what is going on:"]},{"cell_type":"code","metadata":{"id":"tEpREfP_nDwP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"07bf7ec2-82b2-43fb-e921-8c1729ab05a9","executionInfo":{"status":"ok","timestamp":1580074044673,"user_tz":300,"elapsed":4386,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["! cat debug/ex1a.py"],"execution_count":18,"outputs":[{"output_type":"stream","text":["import numpy as np\n","\n","from numba import cuda\n","\n","@cuda.jit\n","def histogram(x, xmin, xmax, histogram_out):\n","    nbins = histogram_out.shape[0]\n","    bin_width = (xmax - xmin) / nbins\n","\n","    start = cuda.grid(1)\n","    stride = cuda.gridsize(1)\n","\n","    for i in range(start, x.shape[0], stride):\n","        bin_number = np.int32((x[i] - xmin)/bin_width)\n","        if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n","            histogram_out[bin_number] += 1\n","            print('in range', x[i], bin_number)\n","        else:\n","            print('out of range', x[i], bin_number)\n","\n","x = np.random.normal(size=50, loc=0, scale=1).astype(np.float32)\n","xmin = np.float32(-4.0)\n","xmax = np.float32(4.0)\n","histogram_out = np.zeros(shape=10, dtype=np.int32)\n","\n","histogram[64, 64](x, xmin, xmax, histogram_out)\n","\n","print('input count:', x.shape[0])\n","print('histogram:', histogram_out)\n","print('count:', histogram_out.sum())\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JslN67SCnDwT","colab_type":"text"},"source":["This kernel will print every value and bin number it calculates.  Looking at one of the print statements, we see that `print` supports constant strings, and scalar values:\n","\n","``` python\n","print('in range', x[i], bin_number)\n","```\n","\n","String substitution (using C printf syntax or the newer `format()` syntax) is not supported.  If we run this script we see:"]},{"cell_type":"code","metadata":{"id":"hRCinH4LnDwV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":918},"outputId":"078abb06-1a3e-42f5-ae4f-caa557155f16","executionInfo":{"status":"ok","timestamp":1580074101823,"user_tz":300,"elapsed":5570,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["! python debug/ex1a.py"],"execution_count":19,"outputs":[{"output_type":"stream","text":["in range -0.266020 4\n","in range -1.461229 3\n","in range 0.243300 5\n","in range -2.697369 1\n","in range 0.687623 5\n","in range 0.190087 5\n","in range 0.681347 5\n","in range -1.164456 3\n","in range 1.487736 6\n","in range 1.091735 6\n","in range -0.575595 4\n","in range -1.527834 3\n","in range 0.210925 5\n","in range 1.293246 6\n","in range 0.450459 5\n","in range -1.376990 3\n","in range -0.181046 4\n","in range 0.745920 5\n","in range 0.716480 5\n","in range 0.100972 5\n","in range -0.145211 4\n","in range 0.251884 5\n","in range 0.504600 5\n","in range 1.172086 6\n","in range -1.041018 3\n","in range -0.699547 4\n","in range 0.122336 5\n","in range 0.113970 5\n","in range 0.313770 5\n","in range 0.746407 5\n","in range 0.532926 5\n","in range 1.013968 6\n","in range -1.262035 3\n","in range 1.134649 6\n","in range 0.147093 5\n","in range 0.386830 5\n","in range -1.304669 3\n","in range 0.384808 5\n","in range 0.716895 5\n","in range -1.434782 3\n","in range -0.570925 4\n","in range 1.363075 6\n","in range 1.986258 7\n","in range 0.419999 5\n","in range 1.146053 6\n","in range 0.016555 5\n","in range -0.426140 4\n","in range 0.843819 6\n","in range 0.266292 5\n","in range 0.721192 5\n","input count: 50\n","histogram: [0 1 0 1 1 1 1 1 0 0]\n","count: 6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R5XPKjkynDwZ","colab_type":"text"},"source":["Scanning down that output, we see that all 50 values should be in range.  Clearly we have some kind of race condition updating the histogram.  In fact, the culprit line is:\n","\n","``` python\n","histogram_out[bin_number] += 1\n","```\n","\n","which should be (as you may have seen in a previous exercise)\n","\n","``` python\n","cuda.atomic.add(histogram_out, bin_number, 1)\n","```"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"OYNd-wV5nDwb","colab_type":"text"},"source":["## CUDA Simulator\n","\n","Back in the early days of CUDA, `nvcc` had an \"emulator\" mode that would execute CUDA code on the CPU for debugging.  That functionality was dropped in later CUDA releases after `cuda-gdb` was created.  There isn't a debugger for CUDA+Python, so Numba includes a \"CUDA simulator\" in Numba that runs your CUDA code with the Python interpreter on the host CPU.  This allows you to debug the logic of your code using Python modules and functions that would otherwise be not allowed by the compile.\n","\n","A very common use case is to start the Python debugger inside one thread of a CUDA kernel:\n","``` python\n","import numpy as np\n","\n","from numba import cuda\n","\n","@cuda.jit\n","def histogram(x, xmin, xmax, histogram_out):\n","    nbins = histogram_out.shape[0]\n","    bin_width = (xmax - xmin) / nbins\n","\n","    start = cuda.grid(1)\n","    stride = cuda.gridsize(1)\n","\n","    ### DEBUG FIRST THREAD\n","    if start == 0:\n","        from pdb import set_trace; set_trace()\n","    ###\n","\n","    for i in range(start, x.shape[0], stride):\n","        bin_number = np.int32((x[i] + xmin)/bin_width)\n","\n","        if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n","            cuda.atomic.add(histogram_out, bin_number, 1)\n","\n","x = np.random.normal(size=50, loc=0, scale=1).astype(np.float32)\n","xmin = np.float32(-4.0)\n","xmax = np.float32(4.0)\n","histogram_out = np.zeros(shape=10, dtype=np.int32)\n","\n","histogram[64, 64](x, xmin, xmax, histogram_out)\n","\n","print('input count:', x.shape[0])\n","print('histogram:', histogram_out)\n","print('count:', histogram_out.sum())\n","```\n","\n","This code allows a debug session like the following to take place:\n","```\n","(gtc2017) 0179-sseibert:gtc2017-numba sseibert$ NUMBA_ENABLE_CUDASIM=1 python debug/ex2.py\n","> /Users/sseibert/continuum/conferences/gtc2017-numba/debug/ex2.py(18)histogram()\n","-> for i in range(start, x.shape[0], stride):\n","(Pdb) n\n","> /Users/sseibert/continuum/conferences/gtc2017-numba/debug/ex2.py(19)histogram()\n","-> bin_number = np.int32((x[i] + xmin)/bin_width)\n","(Pdb) n\n","> /Users/sseibert/continuum/conferences/gtc2017-numba/debug/ex2.py(21)histogram()\n","-> if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n","(Pdb) p bin_number, x[i]\n","(-6, -1.4435024)\n","(Pdb) p x[i], xmin, bin_width\n","(-1.4435024, -4.0, 0.80000000000000004)\n","(Pdb) p (x[i] - xmin) / bin_width\n","3.1956219673156738\n","(Pdb) q\n","```"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"EXnm1oiFnDwd","colab_type":"text"},"source":["## CUDA Memcheck\n","\n","Another common error occurs when a CUDA kernel has an invalid memory access, typically caused by running off the end of an array.  The full CUDA toolkit from NVIDIA (not the `cudatoolkit` conda package) contain a utility called `cuda-memcheck` that can check for a wide range of memory access mistakes in CUDA code.\n","\n","Let's debug the following code:"]},{"cell_type":"code","metadata":{"id":"wAyWM9OdnDwe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"outputId":"0ea486b9-a9d7-43c4-f4c8-f5963882e105","executionInfo":{"status":"ok","timestamp":1580074480197,"user_tz":300,"elapsed":4505,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["! cat debug/ex3.py"],"execution_count":20,"outputs":[{"output_type":"stream","text":["import numpy as np\n","\n","from numba import cuda\n","\n","@cuda.jit\n","def histogram(x, xmin, xmax, histogram_out):\n","    nbins = histogram_out.shape[0]\n","    bin_width = (xmax - xmin) / nbins\n","\n","    start = cuda.grid(1)\n","    stride = cuda.gridsize(1)\n","\n","    for i in range(start, x.shape[0], stride):\n","        bin_number = np.int32((x[i] + xmin)/bin_width)\n","\n","        if bin_number >= 0 or bin_number < histogram_out.shape[0]:\n","            cuda.atomic.add(histogram_out, bin_number, 1)\n","\n","x = np.random.normal(size=50, loc=0, scale=1).astype(np.float32)\n","xmin = np.float32(-4.0)\n","xmax = np.float32(4.0)\n","histogram_out = np.zeros(shape=10, dtype=np.int32)\n","\n","histogram[64, 64](x, xmin, xmax, histogram_out)\n","\n","print('input count:', x.shape[0])\n","print('histogram:', histogram_out)\n","print('count:', histogram_out.sum())\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LSP6yAf0nDwh","colab_type":"code","colab":{}},"source":["! cuda-memcheck python debug/ex3.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AWrUeTNinDwl","colab_type":"text"},"source":["The output of `cuda-memcheck` is clearly showing a problem with our histogram function:\n","```\n","========= Invalid __global__ write of size 4\n","=========     at 0x00000548 in cudapy::__main__::histogram$241(Array<float, int=1, C, mutable, aligned>, float, float, Array<int, int=1, C, mutable, aligned>)\n","```\n","But we don't know which line it is.  To get better error information, we can turn \"debug\" mode on when compiling the kernel, by changing the kernel to look like this:\n","``` python\n","@cuda.jit(debug=True)\n","def histogram(x, xmin, xmax, histogram_out):\n","    nbins = histogram_out.shape[0]\n","```"]},{"cell_type":"code","metadata":{"id":"n_VUZr5onDwm","colab_type":"code","colab":{}},"source":["! cuda-memcheck python debug/ex3a.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJPWcPb1nDwp","colab_type":"text"},"source":["Now we get an error message that includes a source file and line number: `ex3a.py:17`."]},{"cell_type":"code","metadata":{"id":"AnTgaERWnDwq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"c8c9fd7d-c1d2-42a8-a350-d304980c52c7","executionInfo":{"status":"ok","timestamp":1580074752798,"user_tz":300,"elapsed":3714,"user":{"displayName":"Geoffrey Woollard","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjNy-VYGrpEYVchU7TMBqcYGYexvL_pBIe7j5R=s64","userId":"09068754665017449583"}}},"source":["! cat -n debug/ex3a.py | grep -C 2 \"17\""],"execution_count":23,"outputs":[{"output_type":"stream","text":["    15\t\n","    16\t        if bin_number >= 0 or bin_number < histogram_out.shape[0]:\n","    17\t            cuda.atomic.add(histogram_out, bin_number, 1)\n","    18\t\n","    19\tx = np.random.normal(size=50, loc=0, scale=1).astype(np.float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XMRNdqbFnDww","colab_type":"text"},"source":["At this point, we might realize that our if statement incorrect has an `or` instead of an `and`.\n","\n","`cuda-memcheck` has different modes for detecting different kinds of problems (similar to `valgrind` for debugging CPU memory access errors).  Take a look at the documentation for more information: http://docs.nvidia.com/cuda/cuda-memcheck/"]},{"cell_type":"code","metadata":{"id":"z-YpWPwAnDww","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}